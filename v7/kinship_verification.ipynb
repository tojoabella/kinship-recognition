{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kinship_verification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4g8yMLqtS3W"
      },
      "source": [
        "#**Kinship Verification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWf8L2-Ru6ZE"
      },
      "source": [
        "MOUNT GOOGLE DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D44W7Bd6ALSQ",
        "outputId": "d0e32f07-6f49-4708-b155-f5ef05e923b7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ribPmcZau-vR"
      },
      "source": [
        "INSTALL LIBS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS3ZhSjIAGgt"
      },
      "source": [
        "%%capture\n",
        "!pip install keras_vggface\n",
        "!pip install keras_applications"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4yFxckrAAZx"
      },
      "source": [
        "from collections import defaultdict\n",
        "from glob import glob\n",
        "from random import choice, sample\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import cv2\n",
        "from imageio import imread\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract, Conv2D, Lambda, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.vggface import VGGFace"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXViO7APvFYW"
      },
      "source": [
        "TRAIN AND VALIDATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLuyuKKBAWMf"
      },
      "source": [
        "train_file_path = \"/gdrive/MyDrive/Kinship Recognition Starter/train_ds.csv\"\n",
        "train_folders_path = \"/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/\"\n",
        "\n",
        "# All images belonging to families F09** will be used to create the validation set while training the model\n",
        "# For final submission, you can add these to the training data as well\n",
        "val_famillies = \"F09\"\n",
        "\n",
        "all_images = glob(train_folders_path + \"*/*/*.jpg\") #all images\n",
        "train_images = [x for x in all_images if val_famillies not in x] #all images except for F09*\n",
        "val_images = [x for x in all_images if val_famillies in x] #all images that are F09*\n",
        "\n",
        "#for relationships for train and val for model.fit\n",
        "ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images] #family/member/ for all images\n",
        "\n",
        "#for model.fit\n",
        "train_person_to_images_map = defaultdict(list)\n",
        "for x in train_images:\n",
        "    train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x) #add a training person to map\n",
        "\n",
        "#for model.fit\n",
        "val_person_to_images_map = defaultdict(list) \n",
        "for x in val_images:\n",
        "    val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x) #add a validation person to map\n",
        "\n",
        "#for train and val for model.fit\n",
        "relationships = pd.read_csv(train_file_path)\n",
        "relationships = list(zip(relationships.p1.values, relationships.p2.values, relationships.relationship.values))\n",
        "relationships = [(x[0],x[1],x[2]) for x in relationships if x[0][:10] in ppl and x[1][:10] in ppl]\n",
        "\n",
        "#for model.fit\n",
        "train = [x for x in relationships if val_famillies not in x[0]]\n",
        "val = [x for x in relationships if val_famillies in x[0]]\n",
        "\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def read_img(path):\n",
        "    img = image.load_img(path, target_size=(224, 224))\n",
        "    img = np.array(img).astype(np.float)\n",
        "    return preprocess_input(img, version=2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWXX-YHlW4xX"
      },
      "source": [
        "GENERATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWh7uGe1EFXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "6d47c518-33fc-4714-cc04-b1e58b3f372b"
      },
      "source": [
        "####DO THIS GENERATOR #####\n",
        "\n",
        "#import copy\n",
        "#import os\n",
        "\n",
        "from random import choice\n",
        "#v3\n",
        "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
        "    while True:\n",
        "        batch_tuples = sample(list_tuples, batch_size) #[('F0123/MID1/P01276_face0.jpg', 'F0644/MID2/P06777_face5.jpg', 0),...]\n",
        "        \n",
        "        labels = []\n",
        "        X1 = []\n",
        "        X2 = []\n",
        "        for tup in batch_tuples:\n",
        "            temp1 = tup[0].split('/')\n",
        "            person1 = temp1[0] + '/' + temp1[1] #person1: /F0123/MID1\n",
        "            temp2 = tup[1].split('/')\n",
        "            person2 = temp2[0] + '/' + temp2[1] #person2: /F0123/MID1\n",
        "            \n",
        "            person1_path = person_to_images_map[person1]\n",
        "            person2_path = person_to_images_map[person2]\n",
        "            length = len(person1_path) if len(person1_path) < len(person2_path) else len(person2_path)\n",
        "            length = min(2, length)\n",
        "\n",
        "            for i in range(length):\n",
        "                X1.append(choice(person1_path))\n",
        "                X2.append(choice(person2_path))\n",
        "                labels.append(tup[2])\n",
        "\n",
        "        X1 = np.array([read_img(x) for x in X1])\n",
        "\n",
        "        X2 = np.array([read_img(x) for x in X2])\n",
        "\n",
        "        yield [X1, X2], np.array(labels)\n",
        "\n",
        "'''\n",
        "#v2\n",
        "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
        "    while True:\n",
        "        batch_tuples = sample(list_tuples, batch_size) #[('F0123/MID1/P01276_face0.jpg', 'F0644/MID2/P06777_face5.jpg', 0),...]\n",
        "        \n",
        "        labels = []\n",
        "        X1 = []\n",
        "        X2 = []\n",
        "        for tup in batch_tuples:\n",
        "            temp1 = tup[0].split('/')\n",
        "            person1 = temp1[0] + '/' + temp1[1] #person1: /F0123/MID1\n",
        "            temp2 = tup[1].split('/')\n",
        "            person2 = temp2[0] + '/' + temp2[1] #person2: /F0123/MID1\n",
        "\n",
        "            imgs_person1 = os.listdir(train_folders_path + person1) #imgs_person1: [P1, P2, P3...]\n",
        "            imgs_person2 = os.listdir(train_folders_path + person2)\n",
        "            length = len(imgs_person1)\n",
        "            length = len(imgs_person2) if len(imgs_person2) < length else length\n",
        "            length = min(2, length)\n",
        "\n",
        "            for i in range(length):\n",
        "                X1.append(person1 + '/' + imgs_person1[i]) #X1: [/F0123/MID1/P..., ...] 'length' times\n",
        "                X2.append(person2 + '/' + imgs_person2[i])\n",
        "                labels.append(tup[2])\n",
        "\n",
        "        X1 = np.array([read_img(train_folders_path + x) for x in X1])\n",
        "\n",
        "        X2 = np.array([read_img(train_folders_path + x) for x in X2])\n",
        "\n",
        "        yield [X1, X2], np.array(labels)\n",
        "'''\n",
        "'''\n",
        "#v1\n",
        "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
        "    ppl = list(person_to_images_map.keys())\n",
        "    while True:\n",
        "        batch_tuples = sample(list_tuples, batch_size)\n",
        "        \n",
        "        # All the samples are taken from train_ds.csv, labels are in the labels column\n",
        "        labels = []\n",
        "        for tup in batch_tuples:\n",
        "          labels.append(tup[2])\n",
        "\n",
        "        X1 = [x[0] for x in batch_tuples]\n",
        "        X1 = np.array([read_img(train_folders_path + x) for x in X1])\n",
        "\n",
        "        X2 = [x[1] for x in batch_tuples]\n",
        "        X2 = np.array([read_img(train_folders_path + x) for x in X2])\n",
        "\n",
        "        yield [X1, X2], np.array(labels)\n",
        "'''"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#v1\\ndef gen(list_tuples, person_to_images_map, batch_size=16):\\n    ppl = list(person_to_images_map.keys())\\n    while True:\\n        batch_tuples = sample(list_tuples, batch_size)\\n        \\n        # All the samples are taken from train_ds.csv, labels are in the labels column\\n        labels = []\\n        for tup in batch_tuples:\\n          labels.append(tup[2])\\n\\n        X1 = [x[0] for x in batch_tuples]\\n        X1 = np.array([read_img(train_folders_path + x) for x in X1])\\n\\n        X2 = [x[1] for x in batch_tuples]\\n        X2 = np.array([read_img(train_folders_path + x) for x in X2])\\n\\n        yield [X1, X2], np.array(labels)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDFBatfW_vTe",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "\n",
        "###FACENET FAILS\n",
        "'''\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from keras.models import load_model\n",
        "\n",
        "facenet_model = load_model('facenet_keras.h5')\n",
        "facenet_model.load_weights('facenet_keras_weights.h5')\n",
        "for layer in facenet_model.layers[:-3]:\n",
        "    layer.trainable = True\n",
        "facenet_model.summary()\n",
        "'''\n",
        "'''\n",
        "new_layer = Dense(10, activation='softmax', name='my_dense')\n",
        "\n",
        "inp = facenet_model.input\n",
        "out = new_layer(facenet_model.layers[-1].output)\n",
        "\n",
        "model2 = Model(inp, out)\n",
        "model2.summary(line_length=150)\n",
        "'''\n",
        "'''\n",
        "model_path = '/gdrive/MyDrive/facenet_keras.h5'\n",
        "model_fn = load_model(model_path)\n",
        "for layer in model_fn.layers[:-3]:\n",
        "    layer.trainable = True\n",
        "model_vgg = VGGFace(model='resnet50', include_top=False)\n",
        "for layer in model_vgg.layers[:-3]:\n",
        "    layer.trainable = True\n",
        "\n",
        "def lol():\n",
        "    input_1 = Input(shape=(IMG_SIZE_FN, IMG_SIZE_FN, 3))\n",
        "    input_2 = Input(shape=(IMG_SIZE_FN, IMG_SIZE_FN, 3))\n",
        "    input_3 = Input(shape=(IMG_SIZE_VGG, IMG_SIZE_VGG, 3))\n",
        "    input_4 = Input(shape=(IMG_SIZE_VGG, IMG_SIZE_VGG, 3))\n",
        "\n",
        "    x1 = model_fn(input_1)\n",
        "    x2 = model_fn(input_2)\n",
        "    x3 = model_vgg(input_3)\n",
        "    x4 = model_vgg(input_4)\n",
        "    \n",
        "    x1 = Reshape((1, 1 ,128))(x1)\n",
        "    x2 = Reshape((1, 1 ,128))(x2)\n",
        "    x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n",
        "    x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
        "\n",
        "    x1t = Lambda(lambda tensor  : K.square(tensor))(x1)\n",
        "    x2t = Lambda(lambda tensor  : K.square(tensor))(x2)\n",
        "    x3t = Lambda(lambda tensor  : K.square(tensor))(x3)\n",
        "    x4t = Lambda(lambda tensor  : K.square(tensor))(x4)\n",
        "    \n",
        "    merged_add_fn = Add()([x1, x2])\n",
        "    merged_add_vgg = Add()([x3, x4])\n",
        "    merged_sub1_fn = Subtract()([x1,x2])\n",
        "    merged_sub1_vgg = Subtract()([x3,x4])\n",
        "    merged_sub2_fn = Subtract()([x2,x1])\n",
        "    merged_sub2_vgg = Subtract()([x4,x3])\n",
        "    merged_mul1_fn = Multiply()([x1,x2])\n",
        "    merged_mul1_vgg = Multiply()([x3,x4])\n",
        "    merged_sq1_fn = Add()([x1t,x2t])\n",
        "    merged_sq1_vgg = Add()([x3t,x4t])\n",
        "    merged_sqrt_fn = Lambda(lambda tensor  : signed_sqrt(tensor))(merged_mul1_fn)\n",
        "    merged_sqrt_vgg = Lambda(lambda tensor  : signed_sqrt(tensor))(merged_mul1_vgg)\n",
        "\n",
        "    \n",
        "    merged_add_vgg = Conv2D(128 , [1,1] )(merged_add_vgg)\n",
        "    merged_sub1_vgg = Conv2D(128 , [1,1] )(merged_sub1_vgg)\n",
        "    merged_sub2_vgg = Conv2D(128 , [1,1] )(merged_sub2_vgg)\n",
        "    merged_mul1_vgg = Conv2D(128 , [1,1] )(merged_mul1_vgg)\n",
        "    merged_sq1_vgg = Conv2D(128 , [1,1] )(merged_sq1_vgg)\n",
        "    merged_sqrt_vgg = Conv2D(128 , [1,1] )(merged_sqrt_vgg)\n",
        "    \n",
        "    merged = Concatenate(axis=-1)([Flatten()(merged_add_vgg), (merged_add_fn), Flatten()(merged_sub1_vgg), (merged_sub1_fn),\n",
        "                                   Flatten()(merged_sub2_vgg), (merged_sub2_fn), Flatten()(merged_mul1_vgg), (merged_mul1_fn), \n",
        "                                   Flatten()(merged_sq1_vgg), (merged_sq1_fn), Flatten()(merged_sqrt_vgg), (merged_sqrt_fn)])\n",
        "    \n",
        "    merged = Dense(100, activation=\"relu\")(merged)\n",
        "    merged = Dropout(0.1)(merged)\n",
        "    merged = Dense(25, activation=\"relu\")(merged)\n",
        "    merged = Dropout(0.1)(merged)\n",
        "    out = Dense(1, activation=\"sigmoid\")(merged)\n",
        "\n",
        "    model = Model([input_1, input_2, input_3, input_4], out)\n",
        "\n",
        "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "    '''\n",
        "    '''\n",
        "def signed_sqrt(x):\n",
        "    return K.sign(x)*K.sqrt(K.abs(x)+1e-9)\n",
        "    '''\n",
        "\n",
        "'''\n",
        "def baseline_model():\n",
        "    #FACENET\n",
        "    facenet_model = load_model('/gdrive/MyDrive/facenet_keras.h5')\n",
        "    for layer in facenet_model.layers[:-3]:\n",
        "        layer.trainable = True\n",
        "    #input\n",
        "    fc_input_1 = Input(shape=(160, 160, 3))        \n",
        "    fc_input_2 = Input(shape=(160, 160, 3))        \n",
        "    #starting model\n",
        "    fn_x1 = facenet_model(fc_input_1)\n",
        "    fn_x2 = facenet_model(fc_input_2)\n",
        "    #reshaping image array for global max pool layer\n",
        "    fn_x1 = Reshape((1, 1 ,128))(fn_x1) \n",
        "    fn_x2 = Reshape((1, 1 ,128))(fn_x2)\n",
        "    #combining inputs\n",
        "    fn_x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(fn_x1), GlobalAvgPool2D()(fn_x1)])\n",
        "    fn_x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(fn_x2), GlobalAvgPool2D()(fn_x2)])\n",
        "    #adding potential features, concat to final layer before dense\n",
        "    fn_add = Add()([fn_x1, fn_x2])\n",
        "    fn_product = Multiply()([fn_x1,fn_x2])\n",
        "    fn_x = Concatenate(axis=-1)([fn_add, fn_product])\n",
        "'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB4_fhomW-hl"
      },
      "source": [
        "MODEL ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BBZJpieAi7Y"
      },
      "source": [
        "from tensorflow.keras.layers import Flatten, Add, BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "\n",
        "def baseline_model():\n",
        "\n",
        "    ###VGG###\n",
        "    vgg_model = VGGFace(model='vgg16', include_top=False)\n",
        "    for x in vgg_model.layers[:-3]:\n",
        "        x.trainable = True\n",
        "    vgg_input_1 = Input(shape=(224, 224, 3))\n",
        "    vgg_input_2 = Input(shape=(224, 224, 3))\n",
        "    vgg_x1 = BatchNormalization()(vgg_input_1)\n",
        "    vgg_x2 = BatchNormalization()(vgg_input_2)\n",
        "    vgg_x1 = vgg_model(vgg_input_1)\n",
        "    vgg_x2 = vgg_model(vgg_input_2)\n",
        "    #flatten inputs\n",
        "    vgg_x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(vgg_x1), GlobalAvgPool2D()(vgg_x1)])\n",
        "    vgg_x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(vgg_x2), GlobalAvgPool2D()(vgg_x2)])\n",
        "    #adding layers\n",
        "    vgg_x3 = Subtract()([vgg_x1, vgg_x2]) #substract x1 and x2\n",
        "    vgg_x3 = Multiply()([vgg_x3, vgg_x3]) #then square it\n",
        "    vgg_x = Multiply()([vgg_x1, vgg_x2]) #multiply x1 and x2\n",
        "    vgg_x = Concatenate(axis=-1)([vgg_x, vgg_x3]) #concatenate (multiply x1 and x2) with (substract x1 and x2, then square)\n",
        "    vgg_x = Dense(100, activation=\"relu\")(vgg_x)\n",
        "    vgg_x = Dropout(0.01)(vgg_x)\n",
        "\n",
        "    out = Dense(1, activation=\"sigmoid\")(vgg_x)\n",
        "    \n",
        "    model = Model([vgg_input_1, vgg_input_2], out)\n",
        "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC3TNCLWx5RC"
      },
      "source": [
        "MODEL AND CHECKPOINTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YEQ0Q6Ui6NP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "418ca119-3397-49fd-b257-7a38e76ed358"
      },
      "source": [
        "'''\n",
        "Save the best model to your drive after each training epoch so that you can come back to it. ReduceLROnPlateau reduces the learning rate when a metric has stopped improving, in this case the validation accuracy. \n",
        "'''\n",
        "file_path = \"/gdrive/MyDrive/vgg_face2.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
        "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.1, patience=20, verbose=1)\n",
        "callbacks_list = [checkpoint, reduce_on_plateau]\n",
        "model = baseline_model()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n",
            "58916864/58909280 [==============================] - 6s 0us/step\n",
            "58925056/58909280 [==============================] - 6s 0us/step\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1_1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1_1/bias:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_1), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1_2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_1), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1_2/bias:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_2), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_2), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1/bias:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_3), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_3), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2/bias:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_4), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_4), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_5), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_5), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_6), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_6), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_7), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_7), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_8), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_8), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_9), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_9), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_10), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_10), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_11), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_11), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_12), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_12), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_13), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1_1/kernel:0' shape=(3, 3, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_13), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1_1/bias:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_14), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1_2/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_14), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1_2/bias:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_15), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1/kernel:0' shape=(3, 3, 64, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_15), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1/bias:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_16), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_16), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2/bias:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_17), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1/kernel:0' shape=(3, 3, 128, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_17), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_18), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_18), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_19), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_19), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3/bias:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_20), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1/kernel:0' shape=(3, 3, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_20), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_21), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_21), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_22), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_22), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_23), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_23), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_24), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_24), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_25), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.bias_add_25), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3/bias:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution (TFOpLambda)  (None, 224, 224, 64) 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_13 (TFOpLambd (None, 224, 224, 64) 0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add (TFOpLambda)     (None, 224, 224, 64) 0           tf.nn.convolution[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_13 (TFOpLambda)  (None, 224, 224, 64) 0           tf.nn.convolution_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu (TFOpLambda)         (None, 224, 224, 64) 0           tf.nn.bias_add[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_13 (TFOpLambda)      (None, 224, 224, 64) 0           tf.nn.bias_add_13[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_1 (TFOpLambda (None, 224, 224, 64) 0           tf.nn.relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_14 (TFOpLambd (None, 224, 224, 64) 0           tf.nn.relu_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_1 (TFOpLambda)   (None, 224, 224, 64) 0           tf.nn.convolution_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_14 (TFOpLambda)  (None, 224, 224, 64) 0           tf.nn.convolution_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_1 (TFOpLambda)       (None, 224, 224, 64) 0           tf.nn.bias_add_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_14 (TFOpLambda)      (None, 224, 224, 64) 0           tf.nn.bias_add_14[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool (TFOpL (None, 112, 112, 64) 0           tf.nn.relu_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_5 (TFO (None, 112, 112, 64) 0           tf.nn.relu_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_2 (TFOpLambda (None, 112, 112, 128 0           tf.compat.v1.nn.max_pool[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_15 (TFOpLambd (None, 112, 112, 128 0           tf.compat.v1.nn.max_pool_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_2 (TFOpLambda)   (None, 112, 112, 128 0           tf.nn.convolution_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_15 (TFOpLambda)  (None, 112, 112, 128 0           tf.nn.convolution_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_2 (TFOpLambda)       (None, 112, 112, 128 0           tf.nn.bias_add_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_15 (TFOpLambda)      (None, 112, 112, 128 0           tf.nn.bias_add_15[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_3 (TFOpLambda (None, 112, 112, 128 0           tf.nn.relu_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_16 (TFOpLambd (None, 112, 112, 128 0           tf.nn.relu_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_3 (TFOpLambda)   (None, 112, 112, 128 0           tf.nn.convolution_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_16 (TFOpLambda)  (None, 112, 112, 128 0           tf.nn.convolution_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_3 (TFOpLambda)       (None, 112, 112, 128 0           tf.nn.bias_add_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_16 (TFOpLambda)      (None, 112, 112, 128 0           tf.nn.bias_add_16[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_1 (TFO (None, 56, 56, 128)  0           tf.nn.relu_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_6 (TFO (None, 56, 56, 128)  0           tf.nn.relu_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_4 (TFOpLambda (None, 56, 56, 256)  0           tf.compat.v1.nn.max_pool_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_17 (TFOpLambd (None, 56, 56, 256)  0           tf.compat.v1.nn.max_pool_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_4 (TFOpLambda)   (None, 56, 56, 256)  0           tf.nn.convolution_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_17 (TFOpLambda)  (None, 56, 56, 256)  0           tf.nn.convolution_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_4 (TFOpLambda)       (None, 56, 56, 256)  0           tf.nn.bias_add_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_17 (TFOpLambda)      (None, 56, 56, 256)  0           tf.nn.bias_add_17[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_5 (TFOpLambda (None, 56, 56, 256)  0           tf.nn.relu_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_18 (TFOpLambd (None, 56, 56, 256)  0           tf.nn.relu_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_5 (TFOpLambda)   (None, 56, 56, 256)  0           tf.nn.convolution_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_18 (TFOpLambda)  (None, 56, 56, 256)  0           tf.nn.convolution_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_5 (TFOpLambda)       (None, 56, 56, 256)  0           tf.nn.bias_add_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_18 (TFOpLambda)      (None, 56, 56, 256)  0           tf.nn.bias_add_18[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_6 (TFOpLambda (None, 56, 56, 256)  0           tf.nn.relu_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_19 (TFOpLambd (None, 56, 56, 256)  0           tf.nn.relu_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_6 (TFOpLambda)   (None, 56, 56, 256)  0           tf.nn.convolution_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_19 (TFOpLambda)  (None, 56, 56, 256)  0           tf.nn.convolution_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_6 (TFOpLambda)       (None, 56, 56, 256)  0           tf.nn.bias_add_6[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_19 (TFOpLambda)      (None, 56, 56, 256)  0           tf.nn.bias_add_19[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_2 (TFO (None, 28, 28, 256)  0           tf.nn.relu_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_7 (TFO (None, 28, 28, 256)  0           tf.nn.relu_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_7 (TFOpLambda (None, 28, 28, 512)  0           tf.compat.v1.nn.max_pool_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_20 (TFOpLambd (None, 28, 28, 512)  0           tf.compat.v1.nn.max_pool_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_7 (TFOpLambda)   (None, 28, 28, 512)  0           tf.nn.convolution_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_20 (TFOpLambda)  (None, 28, 28, 512)  0           tf.nn.convolution_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_7 (TFOpLambda)       (None, 28, 28, 512)  0           tf.nn.bias_add_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_20 (TFOpLambda)      (None, 28, 28, 512)  0           tf.nn.bias_add_20[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_8 (TFOpLambda (None, 28, 28, 512)  0           tf.nn.relu_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_21 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_8 (TFOpLambda)   (None, 28, 28, 512)  0           tf.nn.convolution_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_21 (TFOpLambda)  (None, 28, 28, 512)  0           tf.nn.convolution_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_8 (TFOpLambda)       (None, 28, 28, 512)  0           tf.nn.bias_add_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_21 (TFOpLambda)      (None, 28, 28, 512)  0           tf.nn.bias_add_21[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_9 (TFOpLambda (None, 28, 28, 512)  0           tf.nn.relu_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_22 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_9 (TFOpLambda)   (None, 28, 28, 512)  0           tf.nn.convolution_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_22 (TFOpLambda)  (None, 28, 28, 512)  0           tf.nn.convolution_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_9 (TFOpLambda)       (None, 28, 28, 512)  0           tf.nn.bias_add_9[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_22 (TFOpLambda)      (None, 28, 28, 512)  0           tf.nn.bias_add_22[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_3 (TFO (None, 14, 14, 512)  0           tf.nn.relu_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_8 (TFO (None, 14, 14, 512)  0           tf.nn.relu_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_10 (TFOpLambd (None, 14, 14, 512)  0           tf.compat.v1.nn.max_pool_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_23 (TFOpLambd (None, 14, 14, 512)  0           tf.compat.v1.nn.max_pool_8[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_10 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_23 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_10 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_10[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_23 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_23[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_11 (TFOpLambd (None, 14, 14, 512)  0           tf.nn.relu_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_24 (TFOpLambd (None, 14, 14, 512)  0           tf.nn.relu_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_11 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_24 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_11 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_11[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_24 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_24[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_12 (TFOpLambd (None, 14, 14, 512)  0           tf.nn.relu_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_25 (TFOpLambd (None, 14, 14, 512)  0           tf.nn.relu_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_12 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.bias_add_25 (TFOpLambda)  (None, 14, 14, 512)  0           tf.nn.convolution_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_12 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_12[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_25 (TFOpLambda)      (None, 14, 14, 512)  0           tf.nn.bias_add_25[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_4 (TFO (None, 7, 7, 512)    0           tf.nn.relu_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_9 (TFO (None, 7, 7, 512)    0           tf.nn.relu_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 512)          0           tf.compat.v1.nn.max_pool_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 512)          0           tf.compat.v1.nn.max_pool_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_1 (GlobalM (None, 512)          0           tf.compat.v1.nn.max_pool_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 512)          0           tf.compat.v1.nn.max_pool_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1024)         0           global_max_pooling2d[0][0]       \n",
            "                                                                 global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1024)         0           global_max_pooling2d_1[0][0]     \n",
            "                                                                 global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "subtract (Subtract)             (None, 1024)         0           concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 1024)         0           concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 1024)         0           subtract[0][0]                   \n",
            "                                                                 subtract[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 2048)         0           multiply_1[0][0]                 \n",
            "                                                                 multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          204900      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 100)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            101         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 205,001\n",
            "Trainable params: 205,001\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpfb9vXxXYFn"
      },
      "source": [
        "FIT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDQn3ZdZAnX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "117ae5d7-08f8-4392-eedd-52b68d2fc618"
      },
      "source": [
        "#model.load_weights('/gdrive/MyDrive/vgg_face2.h5')\n",
        "model.fit(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=False,\n",
        "                validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=10, verbose=1,\n",
        "                workers=1, callbacks=callbacks_list, steps_per_epoch=100, validation_steps=50)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZSMtMvfXd6w"
      },
      "source": [
        "PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIl075HvEfAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04d275d-1fb0-436d-c918-fb27e80ff8d0"
      },
      "source": [
        "# Modify paths as per your need\n",
        "test_path = \"/gdrive/MyDrive/Kinship Recognition Starter/test/\"\n",
        "\n",
        "#model = baseline_model()\n",
        "#model.load_weights(\"/gdrive/MyDrive/vgg_face.h5\")\n",
        "\n",
        "submission = pd.read_csv('/gdrive/MyDrive/Kinship Recognition Starter/test_ds.csv')\n",
        "predictions = []\n",
        "\n",
        "for i in range(0, len(submission.p1.values), 32):\n",
        "    if i%64 == 0:\n",
        "      print(i)\n",
        "    X1 = submission.p1.values[i:i+32]\n",
        "    X1 = np.array([read_img(test_path + x) for x in X1])\n",
        "\n",
        "    X2 = submission.p2.values[i:i+32]\n",
        "    X2 = np.array([read_img(test_path + x) for x in X2])\n",
        "\n",
        "    pred = model.predict([X1, X2]).ravel().tolist()\n",
        "    predictions += pred"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "64\n",
            "128\n",
            "192\n",
            "256\n",
            "320\n",
            "384\n",
            "448\n",
            "512\n",
            "576\n",
            "640\n",
            "704\n",
            "768\n",
            "832\n",
            "896\n",
            "960\n",
            "1024\n",
            "1088\n",
            "1152\n",
            "1216\n",
            "1280\n",
            "1344\n",
            "1408\n",
            "1472\n",
            "1536\n",
            "1600\n",
            "1664\n",
            "1728\n",
            "1792\n",
            "1856\n",
            "1920\n",
            "1984\n",
            "2048\n",
            "2112\n",
            "2176\n",
            "2240\n",
            "2304\n",
            "2368\n",
            "2432\n",
            "2496\n",
            "2560\n",
            "2624\n",
            "2688\n",
            "2752\n",
            "2816\n",
            "2880\n",
            "2944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXyzufq7iZ1g"
      },
      "source": [
        "CREATE CSV TO SUBMIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkFEH-uva9c_"
      },
      "source": [
        "d = {'index': np.arange(0, 3000, 1), 'label':predictions}\n",
        "submissionfile = pd.DataFrame(data=d)\n",
        "submissionfile = submissionfile.round()\n",
        "submissionfile.astype(\"int64\").to_csv(\"/gdrive/MyDrive/tojo2.csv\", index=False)"
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}