{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kinship Recognition Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4g8yMLqtS3W"
      },
      "source": [
        "# **Large-Scale Kinship Recognition Data Challenge: Kinship Verification STARTER NOTEBOOK**\n",
        "\n",
        "We provide framework code to get you started on the competition. The notebook is broken up into three main sections. \n",
        "1. Data Loading & Visualizing\n",
        "2. Data Generator & Model Building\n",
        "3. Training & Testing Model\n",
        "\n",
        "We have done the majority of the heavy lifting by making the data easily and readily accessible through Google Drive. Furthermore, we have made the task easier by creating a dataloader and fully trained end-to-end model that predicts a binary label (0 or 1) denoting whether two faces share a kinship relation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LDDgTAe2w0H"
      },
      "source": [
        "**WARNING: IF YOU HAVE NOT DONE SO**\n",
        "\n",
        "Change to GPU:\n",
        "\n",
        "Runtime --> Change Runtime Type --> GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWf8L2-Ru6ZE"
      },
      "source": [
        "Mount to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D44W7Bd6ALSQ",
        "outputId": "66ced424-cb62-430b-9915-7153a78428cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ribPmcZau-vR"
      },
      "source": [
        "Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS3ZhSjIAGgt"
      },
      "source": [
        "%%capture\n",
        "!pip install keras_vggface\n",
        "!pip install keras_applications"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4yFxckrAAZx"
      },
      "source": [
        "from collections import defaultdict\n",
        "from glob import glob\n",
        "from random import choice, sample\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.vggface import VGGFace"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXViO7APvFYW"
      },
      "source": [
        "[link text](https://)train_relationships.csv contains pairs of image paths which are positive samples (related to each other).\n",
        "\n",
        "train-faces contains the images for training itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItZNSTCVAESV"
      },
      "source": [
        "# Modify paths as per your method of saving them\n",
        "train_file_path = \"/gdrive/MyDrive/Kinship Recognition Starter/train_ds.csv\"\n",
        "#!ls /gdrive/MyDrive/\n",
        "train_folders_path = \"/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/\"\n",
        "# All images belonging to families F09** will be used to create the validation set while training the model\n",
        "# For final submission, you can add these to the training data as well\n",
        "val_famillies = \"F09\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLuyuKKBAWMf"
      },
      "source": [
        "all_images = glob(train_folders_path + \"*/*/*.jpg\") #all images\n",
        "\n",
        "train_images = [x for x in all_images if val_famillies not in x] #all images except for F09*\n",
        "val_images = [x for x in all_images if val_famillies in x] #all images that are F09*\n",
        "\n",
        "ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images] #family/member/ for all images\n",
        "\n",
        "train_person_to_images_map = defaultdict(list)\n",
        "for x in train_images:\n",
        "    train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x) #add a training person to map\n",
        "\n",
        "val_person_to_images_map = defaultdict(list)\n",
        "for x in val_images:\n",
        "    val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x) #add a validation person to map"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HQExgwH95NU",
        "outputId": "49e19879-6838-4d07-e681-5f43c0d2859f"
      },
      "source": [
        "all_images"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03496_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03500_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03497_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03501_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03492_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03499_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03494_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03493_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03495_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03498_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03496_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03500_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03494_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03498_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03495_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID4/P03501_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID4/P03494_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID4/P03495_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID5/P03500_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID5/P03497_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID5/P03498_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID2/P03499_face7.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID2/P03492_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID2/P03493_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09897_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09901_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09900_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09896_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09903_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09895_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09902_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09899_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09897_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09901_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09900_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09903_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09898_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09902_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09904_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID4/P09900_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID4/P09898_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID4/P09904_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID4/P09902_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09901_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09897_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09896_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09895_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09898_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09904_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09899_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05980_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05977_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05971_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05981_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05973_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05982_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05978_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05975_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05983_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05972_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05979_face7.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05974_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05971_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05982_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05973_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05975_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05972_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05971_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05980_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05977_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05975_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05978_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05972_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05974_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05979_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05980_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05971_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05977_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05975_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05978_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05972_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05974_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05971_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05981_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05973_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05983_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05972_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09805_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09811_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09809_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09810_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09813_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09814_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09806_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09812_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID6/P09809_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID3/P09808_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID3/P09813_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID3/P09807_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID4/P09811_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID4/P09809_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID4/P09812_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID5/P09809_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID5/P09812_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09808_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09805_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09810_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09809_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09807_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09813_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09812_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09814_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09806_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID7/P08334_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID8/P08336_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID1/P08334_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID1/P08337_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID1/P08336_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID1/P08341_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID6/P08334_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID3/P08333_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID3/P08334_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID3/P08341_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID4/P08334_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID4/P08341_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID5/P08333_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID5/P08334_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID2/P08337_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID2/P08336_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01390_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09130_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09129_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01396_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09125_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09131_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09128_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01397_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01392_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09126_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01399_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01394_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01393_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09127_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01398_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01395_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01389_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01390_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09130_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01396_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09125_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01397_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09134_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01399_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01394_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09132_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09133_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID4/P01397_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID4/P01398_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID5/P01398_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P01389_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P09125_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P09132_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P01393_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P01395_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID7/P07713_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID9/P07717_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID8/P07717_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07712_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07714_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07713_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07715_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07710_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07716_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07708_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07711_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID6/P07713_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07712_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07714_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07710_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07709_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07716_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07708_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07711_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07717_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07712_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07714_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07715_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07709_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07710_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07711_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID5/P07713_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07712_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07714_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07709_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07710_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07716_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07708_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07415_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07434_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07432_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07426_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07414_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07427_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07433_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07430_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07429_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07417_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07416_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07431_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07428_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID3/P07415_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID3/P07414_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID3/P07416_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID4/P07415_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID4/P07414_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID4/P07417_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID4/P07416_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07415_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07426_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07432_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07414_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07433_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07427_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07429_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07416_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07431_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07428_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04205_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04208_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04211_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04210_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04204_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04207_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04213_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04206_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04212_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04208_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04211_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04210_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04209_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04213_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04212_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04205_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04208_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04204_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04209_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04207_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04213_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04206_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04212_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01792_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01794_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01793_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01795_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01803_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01796_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01804_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID3/P01795_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID3/P01804_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID4/P01797_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01792_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01794_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01793_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01795_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01796_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID7/P07666_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID7/P07665_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07658_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07666_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07663_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07665_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07662_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07664_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID6/P07666_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID6/P07665_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID5/P07663_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID5/P07662_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID5/P07664_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID2/P07658_face6.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID2/P07662_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID2/P07664_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10437_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10437_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10429_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10429_face6.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10435_face6.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10435_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10433_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10433_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10437_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10437_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10429_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10429_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10435_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10433_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10435_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10433_face6.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10437_face6.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10437_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10429_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10429_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10433_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10433_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10435_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10435_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10428_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10432_face9.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10431_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10431_face6.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10428_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10430_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10436_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10430_face6.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P06405_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P06405_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P06410_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10432_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10432_face8.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10437_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10437_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10429_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10436_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10429_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10433_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10433_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10435_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10432_face7.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID11/P10432_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID11/P10432_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10428_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10431_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10428_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06401_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10431_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06403_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06403_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06409_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06404_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06409_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10434_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10434_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10431_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06401_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10428_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10428_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06401_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10431_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10436_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10436_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06403_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06403_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06404_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06409_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06409_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10434_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10428_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10431_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10437_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10431_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10429_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10429_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10436_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10435_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10433_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10433_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10432_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10432_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10431_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10437_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10437_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10428_face6.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10431_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10429_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10429_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10436_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10433_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10433_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10435_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10432_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10432_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID2/P10436_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID2/P10430_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10431_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10428_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10431_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10428_face7.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10430_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10430_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID13/P10430_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID13/P10430_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID14/P10430_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID7/P10557_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID1/P10551_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID1/P10554_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID1/P10552_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID1/P10553_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID6/P10556_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID6/P10555_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID3/P10551_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID3/P10553_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID4/P10552_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID4/P10558_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID5/P10560_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID5/P10553_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID2/P10551_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID2/P10559_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID7/P04136_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID8/P04136_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04131_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04137_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04129_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04130_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04136_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04127_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04138_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04132_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04134_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID6/P04127_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID6/P04132_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID3/P04131_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID3/P04129_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID4/P04137_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID4/P04127_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID4/P04132_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID4/P04134_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID5/P04138_face6.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID5/P04127_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID5/P04132_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID5/P04134_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID2/P04131_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID2/P04129_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID2/P04130_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID1/P01819_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID1/P01817_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID1/P01816_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID3/P01816_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID4/P01819_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID2/P01817_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID2/P01816_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08436_face11.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08417_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08430_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08416_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08437_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08431_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08410_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08415_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08418_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08434_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08432_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08413_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08419_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08438_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08412_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08411_face8.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID3/P08441_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID3/P08437_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID3/P08410_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID3/P08442_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08417_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08440_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08439_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08418_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08412_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08417_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08411_face7.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08436_face7.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08430_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08437_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08416_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08431_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08418_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08434_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08415_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08413_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08432_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08438_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09817_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09824_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09823_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09816_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09818_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09815_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09820_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09819_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09817_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09822_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09824_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09823_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09818_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09820_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09819_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID4/P09824_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID4/P09821_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID2/P09815_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID1/P12238_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID1/P12239_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID1/P12237_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12249_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12248_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12245_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12246_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12247_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID3/P12242_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID3/P12243_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID4/P12243_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID5/P12244_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID5/P12243_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12242_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12243_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12245_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12240_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12246_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12241_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09576_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09581_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09577_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09580_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09579_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09583_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09575_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09578_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09582_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09584_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09576_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09577_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09583_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09578_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09575_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09584_face6.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09581_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09577_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09580_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09579_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09575_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09582_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID7/P07904_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID7/P07879_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID9/P07904_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID9/P07879_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID8/P07879_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07895_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07905_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07908_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07893_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07880_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07899_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07902_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07886_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07909_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07892_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07883_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07901_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07897_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07885_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07891_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07896_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07878_face6.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07884_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID6/P07904_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID6/P07879_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID10/P07881_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID10/P07887_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07895_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07887_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07905_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07893_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07881_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07902_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07892_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07880_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07909_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07886_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07894_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07897_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07901_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07883_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07907_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07891_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07896_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07878_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07900_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07884_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07895_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07898_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07893_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07894_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07899_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07880_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07909_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07892_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07901_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07897_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07907_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07888_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07891_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07900_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07896_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07890_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07878_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID5/P07878_face8.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07895_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07898_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07908_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07893_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07905_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07880_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07899_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07892_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07909_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07904_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07894_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07901_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07897_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07891_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07879_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07907_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07883_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07896_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07900_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07878_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07889_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID7/P07978_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07979_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07975_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07982_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07976_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07977_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID6/P07982_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID3/P07978_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID3/P07976_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID4/P07977_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID5/P07979_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID2/P07975_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05615_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05611_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05610_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05609_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05616_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID3/P05616_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05615_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05611_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05610_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05609_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05616_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01700_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01701_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01707_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01699_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01702_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01704_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01698_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01703_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01705_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01700_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01701_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01707_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01699_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01704_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01703_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01701_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01702_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01704_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01698_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01705_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05338_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05335_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05336_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05330_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05337_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID6/P05337_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID3/P05330_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID4/P05330_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID2/P05338_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID2/P05335_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID2/P05336_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID2/P05330_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID7/P04196_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID7/P04201_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID7/P04195_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID8/P04196_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID8/P04195_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04203_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04202_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04197_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04199_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04194_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04201_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04195_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04198_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04200_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID6/P04201_face8.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04196_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04197_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04199_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04201_face7.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04198_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04200_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04195_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04196_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04197_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04201_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04195_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04200_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04196_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04199_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04201_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04200_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04195_face6.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04203_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04197_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04202_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04201_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04194_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04200_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04195_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID1/P10516_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID1/P10522_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID1/P10529_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID3/P10526_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID3/P10516_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID3/P10517_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10519_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10521_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10527_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10518_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10520_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10526_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10528_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10525_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID5/P10523_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID5/P10524_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID2/P10516_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID2/P10522_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID2/P10529_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04741_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04736_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04746_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04740_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04745_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04732_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04739_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04744_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04733_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04738_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04742_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID3/P04733_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04741_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04746_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04740_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04745_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04743_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04744_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04742_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID5/P04745_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID5/P04744_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04736_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04737_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04732_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04739_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04733_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04738_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07195_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07193_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07194_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07192_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07188_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07191_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07196_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07189_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07190_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID3/P07193_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID3/P07194_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID3/P07192_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID3/P07191_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID4/P07195_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID4/P07194_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID4/P07196_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID2/P07194_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID2/P07188_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID2/P07189_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID2/P07190_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04956_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04950_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04949_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04957_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04951_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04953_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID3/P04954_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID3/P04952_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID3/P04953_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID4/P04954_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID4/P04952_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID4/P04955_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID4/P04953_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04956_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04950_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04949_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04957_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04951_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04954_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04952_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04955_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02410_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02405_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02411_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02408_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02412_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02414_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02407_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02413_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID3/P02410_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID3/P02408_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID3/P02412_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID3/P02413_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID4/P02409_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID4/P02411_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID5/P02409_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID5/P02411_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID2/P02410_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID2/P02405_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID2/P02414_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID2/P02407_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00221_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00227_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00220_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00226_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00223_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00225_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00228_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00222_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00224_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00229_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID3/P00221_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID3/P00222_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID3/P00229_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID4/P00225_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID4/P00224_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID4/P00229_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID5/P00228_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID2/P00227_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID2/P00220_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID2/P00226_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID2/P00223_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID7/P04718_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04717_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04720_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04718_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04715_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04719_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04712_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04721_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04714_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID3/P04712_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID3/P04714_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID3/P04721_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID4/P04720_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID4/P04715_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID4/P04714_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04717_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04712_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04719_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04721_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04714_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07041_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07036_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07047_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07040_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07037_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07034_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07039_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07045_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07035_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07038_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07042_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07033_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07044_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07041_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07036_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07040_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07037_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07039_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07034_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07043_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07045_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07035_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07038_face5.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07044_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07036_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07041_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07037_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07040_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07046_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07039_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07034_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07038_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07035_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07041_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07040_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07037_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07039_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07036_face9.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07038_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07035_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07036_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07041_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07047_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07037_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07040_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07046_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07039_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07043_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07035_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07042_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07033_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07038_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08740_face4.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08731_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08737_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08736_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08733_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08735_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08738_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08732_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08739_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08734_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID3/P08731_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID3/P08735_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID3/P08740_face10.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID3/P08739_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08731_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08737_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08740_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08736_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08733_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08735_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08732_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08734_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08731_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08736_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08733_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08738_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08735_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08734_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08740_face9.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06585_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06579_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06581_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06577_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06586_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06580_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06583_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06584_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06578_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06582_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06577_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06579_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06585_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06583_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06578_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06584_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06582_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06581_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06577_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06586_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06580_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02577_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02571_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02568_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02569_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02575_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02573_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02572_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID3/P02577_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID3/P02568_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID3/P02576_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID3/P02569_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID4/P02571_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID4/P02570_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID4/P02574_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID5/P02573_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02577_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02568_face3.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02571_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02576_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02570_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02569_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02575_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02574_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02572_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00727_face1.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00719_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00721_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00720_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00728_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00725_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00723_face2.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00729_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00724_face0.jpg',\n",
              " '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00722_face3.jpg',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSI5FN3RAXXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726ec2ff-a307-4052-efe7-e75cef60cd03"
      },
      "source": [
        "relationships = pd.read_csv(train_file_path)\n",
        "relationships = list(zip(relationships.p1.values, relationships.p2.values, relationships.relationship.values))\n",
        "relationships = [(x[0],x[1],x[2]) for x in relationships if x[0][:10] in ppl and x[1][:10] in ppl]\n",
        "print(relationships[0])\n",
        "\n",
        "train = [x for x in relationships if val_famillies not in x[0]]\n",
        "print(train[0])\n",
        "val = [x for x in relationships if val_famillies in x[0]]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('F0123/MID1/P01276_face0.jpg', 'F0644/MID2/P06777_face5.jpg', 0)\n",
            "('F0123/MID1/P01276_face0.jpg', 'F0644/MID2/P06777_face5.jpg', 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KfHltcuAZcB"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "def read_img(path):\n",
        "    img = image.load_img(path, target_size=(224, 224))\n",
        "    img = np.array(img).astype(np.float)\n",
        "    return preprocess_input(img, version=2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5k69UJzvb26"
      },
      "source": [
        "Define a data generator. Here our data generator will generate a batch of examples which will be used by our model in training. It will generate two images, one for each in the pair as well as a label associated with it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcAZG7JYAdhY"
      },
      "source": [
        "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
        "    ppl = list(person_to_images_map.keys())\n",
        "    while True:\n",
        "        batch_tuples = sample(list_tuples, batch_size)\n",
        "        \n",
        "        # All the samples are taken from train_ds.csv, labels are in the labels column\n",
        "        labels = []\n",
        "        for tup in batch_tuples:\n",
        "          labels.append(tup[2])\n",
        "\n",
        "        X1 = [x[0] for x in batch_tuples]\n",
        "        X1 = np.array([read_img(train_folders_path + x) for x in X1])\n",
        "\n",
        "        X2 = [x[1] for x in batch_tuples]\n",
        "        X2 = np.array([read_img(train_folders_path + x) for x in X2])\n",
        "\n",
        "        yield [X1, X2], np.array(labels)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvPvyRzBw-nt"
      },
      "source": [
        "Here is an ensemble model built with two resnet-50 architectures, pre-trained, with which we can apply transfer leraning on. This model achieves the baseline and the goal is to expand on this work. There have been papers exploring different architectures as well as introducing BatchNormalization among many other techniques to improve how well the model recognizes kinship between two faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BBZJpieAi7Y"
      },
      "source": [
        "def baseline_model():\n",
        "    input_1 = Input(shape=(224, 224, 3))\n",
        "    input_2 = Input(shape=(224, 224, 3))\n",
        "\n",
        "    base_model = VGGFace(model='resnet50', include_top=False)\n",
        "\n",
        "    for x in base_model.layers[:-3]:\n",
        "        x.trainable = True\n",
        "\n",
        "    x1 = base_model(input_1) #reshaping input of model to that of image shapes\n",
        "    x2 = base_model(input_2)\n",
        "\n",
        "    x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)]) #not too sure\n",
        "    x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
        "\n",
        "    x3 = Subtract()([x1, x2]) #substract x1 and x2\n",
        "    x3 = Multiply()([x3, x3]) #then square it\n",
        "\n",
        "    x = Multiply()([x1, x2]) #multiply x1 and x2\n",
        "    x = Concatenate(axis=-1)([x, x3]) #concatenate (multiply x1 and x2) with (substract x1 and x2, then square)\n",
        "\n",
        "    x = Dense(100, activation=\"relu\")(x) #output 100-dimension\n",
        "    x = Dropout(0.05)(x) #adding regularization\n",
        "    out = Dense(1, activation=\"sigmoid\")(x) #output 1 (classification)\n",
        "\n",
        "    model = Model([input_1, input_2], out)\n",
        "\n",
        "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC3TNCLWx5RC"
      },
      "source": [
        "Save the best model to your drive after each training epoch so that you can come back to it. ReduceLROnPlateau reduces the learning rate when a metric has stopped improving, in this case the validation accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YEQ0Q6Ui6NP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c71cfca-afd9-4c0e-9e6b-c0874ce5fee2"
      },
      "source": [
        "file_path = \"/gdrive/MyDrive/vgg_face.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
        "\n",
        "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.1, patience=20, verbose=1)\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_on_plateau]\n",
        "\n",
        "model = baseline_model()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
            "94699520/94694792 [==============================] - 1s 0us/step\n",
            "94707712/94694792 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/kernel:0' shape=(7, 7, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_1), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/kernel:0' shape=(1, 1, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_1), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_2), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_2), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_3), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_4), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_3), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_4), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_5), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_5), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_6), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_6), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_7), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_7), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_8), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_8), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_9), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_9), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_10), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_10), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_11), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/kernel:0' shape=(1, 1, 256, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_11), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_12), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_12), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_13), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/kernel:0' shape=(1, 1, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_14), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_13), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_14), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_15), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_15), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_16), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_16), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_17), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_17), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_18), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_18), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_19), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_19), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_20), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_20), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_21), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_21), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_22), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_22), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_23), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_23), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_24), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/kernel:0' shape=(1, 1, 512, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_24), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_25), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_25), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_26), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/kernel:0' shape=(1, 1, 512, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_27), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_26), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_27), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_28), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_28), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_29), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_29), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_30), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_30), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_31), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_31), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_32), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_32), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_33), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_33), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_34), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_34), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_35), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_35), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_36), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_36), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_37), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_37), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_38), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_38), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_39), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_39), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_40), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_40), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_41), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_41), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_42), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_42), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_43), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/kernel:0' shape=(1, 1, 1024, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_43), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_44), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_44), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_45), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/kernel:0' shape=(1, 1, 1024, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_46), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_45), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_46), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_47), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_47), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_48), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_48), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_49), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_49), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_50), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_50), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_51), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_51), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_52), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_52), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_53), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/kernel:0' shape=(7, 7, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_53), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_54), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/kernel:0' shape=(1, 1, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_54), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_55), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_55), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_56), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_57), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_56), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_57), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_58), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_58), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_59), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_59), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_60), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_60), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_61), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_61), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_62), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_62), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_63), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_63), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_64), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/kernel:0' shape=(1, 1, 256, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_64), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_65), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_65), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_66), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/kernel:0' shape=(1, 1, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_67), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_66), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_67), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_68), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_68), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_69), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_69), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_70), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_70), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_71), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_71), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_72), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_72), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_73), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_73), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_74), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_74), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_75), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_75), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_76), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_76), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_77), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/kernel:0' shape=(1, 1, 512, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_77), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_78), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_78), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_79), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/kernel:0' shape=(1, 1, 512, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_80), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_79), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_80), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_81), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_81), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_82), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_82), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_83), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_83), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_84), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_84), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_85), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_85), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_86), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_86), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_87), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_87), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_88), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_88), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_89), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_89), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_90), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_90), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_91), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_91), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_92), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_92), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_93), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_93), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_94), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_94), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_95), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_95), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_96), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/kernel:0' shape=(1, 1, 1024, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_96), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_97), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_97), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_98), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/kernel:0' shape=(1, 1, 1024, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_99), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_98), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_99), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_100), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_100), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_101), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_101), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_102), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_102), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_103), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_103), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_104), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_104), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_105), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_105), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution (TFOpLambda)  (None, 112, 112, 64) 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_53 (TFOpLambd (None, 112, 112, 64) 0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 112, 112, 64 0           tf.nn.convolution[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 112, 112, 64 0           tf.nn.convolution_53[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu (TFOpLambda)         (None, 112, 112, 64) 0           tf.compat.v1.nn.fused_batch_norm[\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_49 (TFOpLambda)      (None, 112, 112, 64) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool (TFOpL (None, 55, 55, 64)   0           tf.nn.relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_1 (TFO (None, 55, 55, 64)   0           tf.nn.relu_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_1 (TFOpLambda (None, 55, 55, 64)   0           tf.compat.v1.nn.max_pool[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_54 (TFOpLambd (None, 55, 55, 64)   0           tf.compat.v1.nn.max_pool_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_54[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_1 (TFOpLambda)       (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_50 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_2 (TFOpLambda (None, 55, 55, 64)   0           tf.nn.relu_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_55 (TFOpLambd (None, 55, 55, 64)   0           tf.nn.relu_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_55[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_2 (TFOpLambda)       (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_51 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_4 (TFOpLambda (None, 55, 55, 256)  0           tf.nn.relu_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_3 (TFOpLambda (None, 55, 55, 256)  0           tf.compat.v1.nn.max_pool[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_57 (TFOpLambd (None, 55, 55, 256)  0           tf.nn.relu_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_56 (TFOpLambd (None, 55, 55, 256)  0           tf.compat.v1.nn.max_pool_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_57[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_56[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_16 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_3 (TFOpLambda)       (None, 55, 55, 256)  0           tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_52 (TFOpLambda)      (None, 55, 55, 256)  0           tf.__operators__.add_16[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_5 (TFOpLambda (None, 55, 55, 64)   0           tf.nn.relu_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_58 (TFOpLambd (None, 55, 55, 64)   0           tf.nn.relu_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_58[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_4 (TFOpLambda)       (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_53 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_6 (TFOpLambda (None, 55, 55, 64)   0           tf.nn.relu_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_59 (TFOpLambd (None, 55, 55, 64)   0           tf.nn.relu_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_59[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_5 (TFOpLambda)       (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_54 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_7 (TFOpLambda (None, 55, 55, 256)  0           tf.nn.relu_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_60 (TFOpLambd (None, 55, 55, 256)  0           tf.nn.relu_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_60[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_17 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_6 (TFOpLambda)       (None, 55, 55, 256)  0           tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_55 (TFOpLambda)      (None, 55, 55, 256)  0           tf.__operators__.add_17[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_8 (TFOpLambda (None, 55, 55, 64)   0           tf.nn.relu_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_61 (TFOpLambd (None, 55, 55, 64)   0           tf.nn.relu_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_61[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_7 (TFOpLambda)       (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_56 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_9 (TFOpLambda (None, 55, 55, 64)   0           tf.nn.relu_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_62 (TFOpLambd (None, 55, 55, 64)   0           tf.nn.relu_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_62[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_8 (TFOpLambda)       (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_57 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_10 (TFOpLambd (None, 55, 55, 256)  0           tf.nn.relu_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_63 (TFOpLambd (None, 55, 55, 256)  0           tf.nn.relu_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_63[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_18 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_9 (TFOpLambda)       (None, 55, 55, 256)  0           tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_58 (TFOpLambda)      (None, 55, 55, 256)  0           tf.__operators__.add_18[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_11 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_64 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_64[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_10 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_59 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_12 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_65 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_65[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_11 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_60 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_14 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_13 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_67 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_66 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_67[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_66[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_19 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_12 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_61 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_19[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_15 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_68 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_68[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_13 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_62 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_16 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_69 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_14 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_63 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_17 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_70 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_70[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_4 (TFOpLam (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_20 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_15 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_64 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_20[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_18 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_71 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_71[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_16 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_65 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_19 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_72 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_72[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_17 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_66 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_20 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_73 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_73[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_5 (TFOpLam (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_21 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_18 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_67 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_21[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_21 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_74 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_74[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_19 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_68 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_22 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_75 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_75[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_20 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_69 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_23 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_76 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_76[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_6 (TFOpLam (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_22 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_21 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_70 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_22[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_24 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_77 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_77[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_22 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_71 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_25 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_78 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_78[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_23 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_72 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_27 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_26 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_80 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_79 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_80[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_79[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_7 (TFOpLam (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_23 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_24 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_7[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_73 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_23[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_28 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_81 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_81[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_25 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_74 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_29 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_82 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_82[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_26 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_75 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_30 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_83 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_83[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_8 (TFOpLam (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_24 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_27 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_8[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_76 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_24[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_31 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_84 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_84[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_28 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_77 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_32 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_85 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_85[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_29 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_78 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_33 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_86 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_86[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_9 (TFOpLam (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_25 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_30 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_9[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_79 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_25[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_34 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_87 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_87[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_31 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_80 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_35 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_88 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_35[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_88[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_32 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_81 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_36 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_89 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_89[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_10 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_26 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_33 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_10[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_82 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_26[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_37 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_90 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_37[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_90[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_34 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_83 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_38 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_91 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_38[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_91[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_35 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_84 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_39 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_92 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_39[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_92[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_11 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_27 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_36 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_11[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_85 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_27[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_40 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_93 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_40[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_93[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_37 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_86 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_41 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_94 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_41[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_94[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_38 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_87 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_42 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_95 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_42[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_95[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_12 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_28 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_39 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_12[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_88 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_28[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_43 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_96 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_43[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_96[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_40 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_89 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_44 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_97 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_44[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_97[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_41 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_90 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_46 (TFOpLambd (None, 7, 7, 2048)   0           tf.nn.relu_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_45 (TFOpLambd (None, 7, 7, 2048)   0           tf.nn.relu_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_99 (TFOpLambd (None, 7, 7, 2048)   0           tf.nn.relu_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_98 (TFOpLambd (None, 7, 7, 2048)   0           tf.nn.relu_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_46[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_45[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_99[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_98[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_13 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_29 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_42 (TFOpLambda)      (None, 7, 7, 2048)   0           tf.__operators__.add_13[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_91 (TFOpLambda)      (None, 7, 7, 2048)   0           tf.__operators__.add_29[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_47 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_100 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_47[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_100[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_43 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_92 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_48 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_101 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_48[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_101[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_44 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_93 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_49 (TFOpLambd (None, 7, 7, 2048)   0           tf.nn.relu_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_102 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_49[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_102[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_14 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_30 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_45 (TFOpLambda)      (None, 7, 7, 2048)   0           tf.__operators__.add_14[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_94 (TFOpLambda)      (None, 7, 7, 2048)   0           tf.__operators__.add_30[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_50 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_103 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_50[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_103[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_46 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_95 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_51 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_104 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_51[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_104[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_47 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_96 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_52 (TFOpLambd (None, 7, 7, 2048)   0           tf.nn.relu_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_105 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_52[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_105[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_15 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_31 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_48 (TFOpLambda)      (None, 7, 7, 2048)   0           tf.__operators__.add_15[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_97 (TFOpLambda)      (None, 7, 7, 2048)   0           tf.__operators__.add_31[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.avg_pool (TFOpL (None, 1, 1, 2048)   0           tf.nn.relu_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.avg_pool_1 (TFO (None, 1, 1, 2048)   0           tf.nn.relu_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 2048)         0           tf.compat.v1.nn.avg_pool[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           tf.compat.v1.nn.avg_pool[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_1 (GlobalM (None, 2048)         0           tf.compat.v1.nn.avg_pool_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           tf.compat.v1.nn.avg_pool_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4096)         0           global_max_pooling2d[0][0]       \n",
            "                                                                 global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4096)         0           global_max_pooling2d_1[0][0]     \n",
            "                                                                 global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "subtract (Subtract)             (None, 4096)         0           concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 4096)         0           concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 4096)         0           subtract[0][0]                   \n",
            "                                                                 subtract[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8192)         0           multiply_1[0][0]                 \n",
            "                                                                 multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          819300      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 100)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            101         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 819,401\n",
            "Trainable params: 819,401\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqKtezwE6cp5",
        "outputId": "017bf527-936a-4548-daa9-0a06677de6c1"
      },
      "source": [
        "#train: 3-tuple of (face 1, face 2, relationship between people of faces)\n",
        "#ie: ('F0123/MID1/P01276_face0.jpg', 'F0644/MID2/P06777_face5.jpg', 0)\n",
        "print(train[0])\n",
        "\n",
        "#train_person_to_images_map: map of (person : path of images of that person)\n",
        "# ie. ['/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03496_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03500_face2.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03497_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03501_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03492_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03499_face5.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03494_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03493_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03495_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03498_face0.jpg']\n",
        "print(train_person_to_images_map['F0330/MID1'])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('F0123/MID1/P01276_face0.jpg', 'F0644/MID2/P06777_face5.jpg', 0)\n",
            "['/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03496_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03500_face2.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03497_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03501_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03492_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03499_face5.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03494_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03493_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03495_face0.jpg', '/gdrive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03498_face0.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDQn3ZdZAnX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1ec889-e883-46e0-9688-1204615040f3"
      },
      "source": [
        "model.fit(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=False,\n",
        "                validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=25, verbose=1,\n",
        "                workers=1, callbacks=callbacks_list, steps_per_epoch=100, validation_steps=50)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "100/100 [==============================] - 533s 5s/step - loss: 6.3807 - acc: 0.5631 - val_loss: 6.0828 - val_acc: 0.5462\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.54625, saving model to /gdrive/MyDrive/vgg_face.h5\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 208s 2s/step - loss: 3.3924 - acc: 0.6950 - val_loss: 4.9002 - val_acc: 0.6150\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.54625 to 0.61500, saving model to /gdrive/MyDrive/vgg_face.h5\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 121s 1s/step - loss: 2.2188 - acc: 0.7894 - val_loss: 4.5255 - val_acc: 0.6200\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.61500 to 0.62000, saving model to /gdrive/MyDrive/vgg_face.h5\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 83s 842ms/step - loss: 1.6836 - acc: 0.8263 - val_loss: 5.0644 - val_acc: 0.6325\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.62000 to 0.63250, saving model to /gdrive/MyDrive/vgg_face.h5\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 60s 606ms/step - loss: 1.1993 - acc: 0.8619 - val_loss: 4.3175 - val_acc: 0.6438\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.63250 to 0.64375, saving model to /gdrive/MyDrive/vgg_face.h5\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 54s 544ms/step - loss: 1.0100 - acc: 0.8806 - val_loss: 4.5534 - val_acc: 0.6488\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.64375 to 0.64875, saving model to /gdrive/MyDrive/vgg_face.h5\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 42s 424ms/step - loss: 0.9280 - acc: 0.8919 - val_loss: 4.2330 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.64875 to 0.66250, saving model to /gdrive/MyDrive/vgg_face.h5\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 35s 355ms/step - loss: 0.7146 - acc: 0.9112 - val_loss: 4.5759 - val_acc: 0.6687\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.66250 to 0.66875, saving model to /gdrive/MyDrive/vgg_face.h5\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 32s 326ms/step - loss: 0.5135 - acc: 0.9350 - val_loss: 5.2922 - val_acc: 0.6375\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.66875\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 31s 316ms/step - loss: 0.4446 - acc: 0.9362 - val_loss: 4.7101 - val_acc: 0.6750\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.66875 to 0.67500, saving model to /gdrive/MyDrive/vgg_face.h5\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.4700 - acc: 0.9431 - val_loss: 5.1774 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.67500\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 25s 247ms/step - loss: 0.4651 - acc: 0.9456 - val_loss: 4.5104 - val_acc: 0.6988\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.67500 to 0.69875, saving model to /gdrive/MyDrive/vgg_face.h5\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.3251 - acc: 0.9619 - val_loss: 5.9068 - val_acc: 0.6825\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.69875\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 25s 257ms/step - loss: 0.3890 - acc: 0.9519 - val_loss: 5.1313 - val_acc: 0.6938\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.69875\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 20s 203ms/step - loss: 0.2728 - acc: 0.9606 - val_loss: 5.5478 - val_acc: 0.6538\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.69875\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.2901 - acc: 0.9625 - val_loss: 5.2273 - val_acc: 0.6562\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.69875\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 25s 247ms/step - loss: 0.2571 - acc: 0.9656 - val_loss: 5.9960 - val_acc: 0.6562\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.69875\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.2171 - acc: 0.9694 - val_loss: 5.5732 - val_acc: 0.6825\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.69875\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.2465 - acc: 0.9719 - val_loss: 6.5801 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.69875\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 21s 215ms/step - loss: 0.2055 - acc: 0.9706 - val_loss: 6.2323 - val_acc: 0.6575\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.69875\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 20s 200ms/step - loss: 0.1174 - acc: 0.9725 - val_loss: 7.6010 - val_acc: 0.6463\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.69875\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.1480 - acc: 0.9781 - val_loss: 6.4566 - val_acc: 0.6725\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.69875\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 21s 211ms/step - loss: 0.1110 - acc: 0.9812 - val_loss: 6.3515 - val_acc: 0.6650\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.69875\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 20s 203ms/step - loss: 0.1108 - acc: 0.9750 - val_loss: 7.0413 - val_acc: 0.6662\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.69875\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 20s 200ms/step - loss: 0.1198 - acc: 0.9825 - val_loss: 7.2589 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.69875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff8dd774950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIl075HvEfAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f000861-d399-4211-b986-821ff2cfeeb3"
      },
      "source": [
        "# Modify paths as per your need\n",
        "test_path = \"/gdrive/MyDrive/Kinship Recognition Starter/test/\"\n",
        "\n",
        "#model = baseline_model()\n",
        "#model.load_weights(\"/gdrive/MyDrive/vgg_face.h5\")\n",
        "\n",
        "submission = pd.read_csv('/gdrive/MyDrive/Kinship Recognition Starter/test_ds.csv')\n",
        "predictions = []\n",
        "\n",
        "for i in range(0, len(submission.p1.values), 32):\n",
        "    X1 = submission.p1.values[i:i+32]\n",
        "    X1 = np.array([read_img(test_path + x) for x in X1])\n",
        "\n",
        "    X2 = submission.p2.values[i:i+32]\n",
        "    X2 = np.array([read_img(test_path + x) for x in X2])\n",
        "\n",
        "    pred = model.predict([X1, X2]).ravel().tolist()\n",
        "    predictions += pred"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_106), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/kernel:0' shape=(7, 7, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_106), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_107), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/kernel:0' shape=(1, 1, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_107), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_108), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_108), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_109), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_110), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_109), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_110), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_111), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_111), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_112), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_112), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_113), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_113), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_114), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_114), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_115), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_115), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_116), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_116), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_117), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/kernel:0' shape=(1, 1, 256, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_117), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_118), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_118), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_119), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/kernel:0' shape=(1, 1, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_120), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_119), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_120), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_121), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_121), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_122), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_122), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_123), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_123), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_124), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_124), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_125), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_125), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_126), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_126), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_127), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_127), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_128), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_128), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_129), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_129), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_130), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/kernel:0' shape=(1, 1, 512, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_130), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_131), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_131), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_132), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/kernel:0' shape=(1, 1, 512, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_133), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_132), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_133), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_134), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_134), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_135), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_135), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_136), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_136), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_137), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_137), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_138), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_138), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_139), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_139), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_140), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_140), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_141), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_141), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_142), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_142), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_143), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_143), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_144), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_144), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_145), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_145), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_146), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_146), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_147), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_147), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_148), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_148), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_149), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/kernel:0' shape=(1, 1, 1024, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_149), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_150), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_150), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_151), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/kernel:0' shape=(1, 1, 1024, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_152), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_151), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_152), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_153), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_153), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_154), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_154), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_155), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_155), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_156), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_156), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_157), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_157), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_158), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_158), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_159), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/kernel:0' shape=(7, 7, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_159), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_160), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/kernel:0' shape=(1, 1, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_160), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_161), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_161), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_162), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_163), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_162), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_163), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_164), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_164), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_165), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_165), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_166), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_166), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_167), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_167), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_168), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_168), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_169), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_169), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_170), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/kernel:0' shape=(1, 1, 256, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_170), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_171), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_171), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_172), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/kernel:0' shape=(1, 1, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_173), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_172), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_173), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_174), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_174), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_175), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_175), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_176), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_176), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_177), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_177), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_178), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_178), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_179), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_179), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_180), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_180), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_181), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_181), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_182), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_182), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_183), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/kernel:0' shape=(1, 1, 512, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_183), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_184), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_184), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_185), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/kernel:0' shape=(1, 1, 512, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_186), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_185), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_186), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_187), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_187), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_188), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_188), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_189), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_189), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_190), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_190), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_191), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_191), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_192), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_192), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_193), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_193), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_194), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_194), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_195), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_195), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_196), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_196), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_197), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_197), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_198), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_198), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_199), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_199), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_200), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_200), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_201), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_201), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_202), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/kernel:0' shape=(1, 1, 1024, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_202), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_203), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_203), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_204), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/kernel:0' shape=(1, 1, 1024, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_205), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_204), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_205), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_206), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_206), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_207), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_207), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_208), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_208), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_209), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_209), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_210), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_210), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_211), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_211), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_106 (TFOpLamb (None, 112, 112, 64) 0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_159 (TFOpLamb (None, 112, 112, 64) 0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 112, 112, 64 0           tf.nn.convolution_106[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 112, 112, 64 0           tf.nn.convolution_159[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_98 (TFOpLambda)      (None, 112, 112, 64) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_147 (TFOpLambda)     (None, 112, 112, 64) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_2 (TFO (None, 55, 55, 64)   0           tf.nn.relu_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_3 (TFO (None, 55, 55, 64)   0           tf.nn.relu_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_107 (TFOpLamb (None, 55, 55, 64)   0           tf.compat.v1.nn.max_pool_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_160 (TFOpLamb (None, 55, 55, 64)   0           tf.compat.v1.nn.max_pool_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_107[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_160[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_99 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_148 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_108 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_161 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_108[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_161[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_100 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_149 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_110 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_109 (TFOpLamb (None, 55, 55, 256)  0           tf.compat.v1.nn.max_pool_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_163 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_162 (TFOpLamb (None, 55, 55, 256)  0           tf.compat.v1.nn.max_pool_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_110[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_109[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_163[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_162[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_32 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_48 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_101 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_32[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_150 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_48[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_111 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_164 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_111[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_164[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_102 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_151 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_112 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_165 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_112[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_165[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_103 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_152 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_113 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_166 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_113[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_166[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_33 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_49 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_104 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_33[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_153 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_49[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_114 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_167 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_114[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_167[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_105 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_154 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_115 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_168 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_115[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_168[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_106 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_155 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_116 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_169 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_116[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_169[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_34 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_50 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_107 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_34[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_156 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_50[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_117 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_170 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_117[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_170[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_108 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_157 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_118 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_171 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_118[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_171[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_109 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_158 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_120 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_119 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_173 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_172 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_120[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_119[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_173[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_172[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_35 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_51 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_110 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_35[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_159 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_51[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_121 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_174 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_121[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_174[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_111 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_160 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_122 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_175 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_122[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_175[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_112 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_161 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_123 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_176 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_123[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_176[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_36 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_52 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_113 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_36[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_162 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_52[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_124 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_177 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_124[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_177[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_114 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_163 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_125 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_178 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_125[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_178[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_115 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_164 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_126 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_179 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_126[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_179[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_37 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_53 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_116 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_37[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_165 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_53[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_127 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_180 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_127[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_180[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_117 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_166 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_128 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_181 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_128[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_181[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_118 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_167 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_129 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_182 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_129[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_182[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_38 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_54 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_119 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_38[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_168 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_54[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_130 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_183 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_130[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_183[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_120 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_169 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_131 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_184 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_131[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_184[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_121 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_170 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_133 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_132 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_186 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_185 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_133[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_132[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_186[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_185[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_39 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_55 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_122 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_39[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_171 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_55[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_134 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_187 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_134[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_187[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_123 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_172 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_135 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_188 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_135[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_188[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_124 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_173 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_136 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_189 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_136[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_189[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_40 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_56 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_125 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_40[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_174 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_56[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_137 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_190 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_137[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_190[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_126 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_175 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_138 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_191 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_138[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_191[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_127 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_176 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_139 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_192 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_139[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_192[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_41 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_57 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_128 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_41[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_177 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_57[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_140 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_193 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_140[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_193[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_129 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_178 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_141 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_194 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_141[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_194[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_130 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_179 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_142 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_195 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_142[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_195[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_42 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_58 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_131 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_42[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_180 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_58[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_143 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_196 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_143[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_196[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_132 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_181 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_144 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_197 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_144[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_197[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_133 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_182 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_145 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_198 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_145[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_198[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_43 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_59 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_134 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_43[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_183 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_59[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_146 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_199 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_146[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_199[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_135 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_184 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_147 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_200 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_147[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_200[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_136 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_185 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_148 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_201 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_148[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_201[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_44 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_60 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_137 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_44[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_186 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_60[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_149 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_202 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_149[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_202[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_138 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_187 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_150 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_203 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_150[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_203[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_139 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_188 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_152 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_151 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_205 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_204 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_152[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_151[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_205[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_204[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_45 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_61 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_140 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_45[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_189 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_61[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_153 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_206 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_153[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_206[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_141 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_190 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_154 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_207 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_154[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_207[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_142 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_191 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_155 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_208 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_155[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_208[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_46 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_62 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_143 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_46[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_192 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_62[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_156 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_209 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_156[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_209[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_144 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_193 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_157 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_210 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_157[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_210[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_145 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_194 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_158 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_211 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_158[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_211[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_47 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_63 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_146 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_47[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_195 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_63[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.avg_pool_2 (TFO (None, 1, 1, 2048)   0           tf.nn.relu_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.avg_pool_3 (TFO (None, 1, 1, 2048)   0           tf.nn.relu_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_2 (GlobalM (None, 2048)         0           tf.compat.v1.nn.avg_pool_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 2048)         0           tf.compat.v1.nn.avg_pool_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_3 (GlobalM (None, 2048)         0           tf.compat.v1.nn.avg_pool_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 2048)         0           tf.compat.v1.nn.avg_pool_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 4096)         0           global_max_pooling2d_2[0][0]     \n",
            "                                                                 global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 4096)         0           global_max_pooling2d_3[0][0]     \n",
            "                                                                 global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "subtract_1 (Subtract)           (None, 4096)         0           concatenate_3[0][0]              \n",
            "                                                                 concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_3 (Multiply)           (None, 4096)         0           concatenate_3[0][0]              \n",
            "                                                                 concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 4096)         0           subtract_1[0][0]                 \n",
            "                                                                 subtract_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 8192)         0           multiply_3[0][0]                 \n",
            "                                                                 multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 100)          819300      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 100)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            101         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 819,401\n",
            "Trainable params: 819,401\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXyzufq7iZ1g"
      },
      "source": [
        "The final predictions will need to be rounded: EG 0.01 rounded to 0 and 0.78 rounded to 1. The simple .round() function is sufficient as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkFEH-uva9c_"
      },
      "source": [
        "d = {'index': np.arange(0, 3000, 1), 'label':predictions}\n",
        "submissionfile = pd.DataFrame(data=d)\n",
        "submissionfile = submissionfile.round()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EbbawPYrchP"
      },
      "source": [
        "submissionfile.astype(\"int64\").to_csv(\"/gdrive/MyDrive/tta2117.csv\", index=False)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNodVS9W4NMB"
      },
      "source": [
        "At this point, download the CSV and submit it on Kaggle to score your predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk0EIVFHQ7F_",
        "outputId": "4ba09a5d-861f-46f1-f57a-6da4f51a3e13"
      },
      "source": [
        "#!chmod -R 777 /gdrive/MyDrive/\"Kinship Recognition Starter\"/\n",
        "#!ls /gdrive/MyDrive/'Kinship Recognition Starter'\n",
        "!ls /gdrive/MyDrive/"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'16-17 SEAS Check list (1).xlsx'\n",
            "'16-17 SEAS Check list.xlsx'\n",
            "'Abella,Terric Music Composition.wav'\n",
            "'Abella, Terric Resume (1).pdf'\n",
            "'Abella, Terric Resume.pdf'\n",
            " Assignments\n",
            "'Calculus Early Transcendentals - James Stewart (Eight Edition).pdf'\n",
            "'Colab Notebooks'\n",
            "'Columbia University 16.m4a'\n",
            " E-Books\n",
            "'EE Lab'\n",
            "'EE Lab #8.gdoc'\n",
            "'EE Mini Project.gdoc'\n",
            "'EE Project.gdoc'\n",
            " finalB_release.ipynb\n",
            "'FINAL. Spring 2019 SCHEDULE.gdoc'\n",
            " foo.txt\n",
            "'Getting started.pdf'\n",
            "'Intro EE Lab #6.gdoc'\n",
            "'japan review session.m4a'\n",
            "'Kinship Recognition Starter'\n",
            "'labeling vouchers1.zip'\n",
            "'Labeling Vouchers edit.zip'\n",
            "\"Malama Hawaii 21-'22\"\n",
            "'P3 Sources (Terric, A)'\n",
            "'Physics Lab'\n",
            "'PLT Proposal.gdoc'\n",
            "'RealityMare-Terric Tojo Abella.wav'\n",
            "'Special Just for Tojo'\n",
            "'Terric - Labeling Vouchers.zip'\n",
            "'Terric Tojo Abella.wav'\n",
            "'tta2117 - Checklist (1).xlsx'\n",
            "'tta2117 - Checklist.xlsx'\n",
            " tta2117.csv\n",
            "'untitled folder.zip'\n",
            " VelocityData.mp4\n",
            " vgg_face.h5\n",
            " Yoshida-FinalPresentation-v7.pptx\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}